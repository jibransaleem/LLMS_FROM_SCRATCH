{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LTIIezB9CbJ2"
      },
      "outputs": [],
      "source": [
        "try :\n",
        "  with open(\"data.txt\" , \"r\") as file:\n",
        "    data  = file.read()\n",
        "except Exception as e :\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.replace(\"\\n\",\"\")\n",
        "data =data.replace(\"\\\\\",\"\")\n",
        "data=data.strip()\n"
      ],
      "metadata": {
        "id": "U7sR0OgKOyzP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try :\n",
        "  import tiktoken\n",
        "except Exception:\n",
        "  !pip install tiktoken\n",
        "  import tiktoken\n",
        ""
      ],
      "metadata": {
        "id": "dmh06ta8O95b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.encoding_for_model(\"gpt2\")"
      ],
      "metadata": {
        "id": "-lct0i1PPsff"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids  = tokenizer.encode(data)\n",
        "print(\"Total tokens using BPT\",len(token_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ8ZOr-oPymf",
        "outputId": "3f201b22-72dd-4f92-ac64-4525b56d69fe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens using BPT 5016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 10\n",
        "\n",
        "print(\"Cumulative Input → Next Token Prediction\\n\" + \"-\"*40)\n",
        "\n",
        "for i in range(1, context_size + 1):\n",
        "    input_text = tokenizer.decode(token_ids[:i])\n",
        "    output_text = tokenizer.decode([token_ids[i]])\n",
        "\n",
        "    print(f\"Input ({i} tokens): {input_text!r}  --->  Next token: {output_text!r}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwW1gaaMQlYQ",
        "outputId": "3e91db5f-7db7-40d9-959a-7caaf420e26f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative Input → Next Token Prediction\n",
            "----------------------------------------\n",
            "Input (1 tokens): 'THE'  --->  Next token: ' VER'\n",
            "\n",
            "Input (2 tokens): 'THE VER'  --->  Next token: 'D'\n",
            "\n",
            "Input (3 tokens): 'THE VERD'  --->  Next token: 'ICT'\n",
            "\n",
            "Input (4 tokens): 'THE VERDICT'  --->  Next token: 'June'\n",
            "\n",
            "Input (5 tokens): 'THE VERDICTJune'  --->  Next token: ' 1908'\n",
            "\n",
            "Input (6 tokens): 'THE VERDICTJune 1908'  --->  Next token: 'I'\n",
            "\n",
            "Input (7 tokens): 'THE VERDICTJune 1908I'  --->  Next token: ' had'\n",
            "\n",
            "Input (8 tokens): 'THE VERDICTJune 1908I had'  --->  Next token: ' always'\n",
            "\n",
            "Input (9 tokens): 'THE VERDICTJune 1908I had always'  --->  Next token: ' thought'\n",
            "\n",
            "Input (10 tokens): 'THE VERDICTJune 1908I had always thought'  --->  Next token: ' Jack'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA LOADER"
      ],
      "metadata": {
        "id": "bgZ986bZfA6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset , DataLoader"
      ],
      "metadata": {
        "id": "-J424NPlVXht"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What stride means\n",
        "\n",
        "Stride = how many tokens you move forward in your dataset when making the next input-output pair.\n",
        "\n",
        "It controls how much overlap there is between consecutive input sequences.\n",
        "\n",
        "# 2️⃣ Example\n",
        "\n",
        "Suppose:\n",
        "\n",
        "- token_ids = [0,1,2,3,4,5,6,7,8,9]\n",
        "- max_length = 4\n",
        "- stride = 1\n",
        "\n",
        "# With stride = 1:\n",
        "- i=0: input  = [0,1,2,3], output = [1,2,3,4]\n",
        "- i=1: input  = [1,2,3,4], output = [2,3,4,5]\n",
        "- i=2: input  = [2,3,4,5], output = [3,4,5,6]\n",
        "\n",
        "\n",
        "✅ Consecutive inputs overlap by 3 tokens (because stride=1, only move 1 token ahead).\n",
        "\n",
        "# With stride = 4:\n",
        "- i=0: input = [0,1,2,3], output = [1,2,3,4]\n",
        "- i=4: input = [4,5,6,7], output = [5,6,7,8]\n",
        "\n",
        "\n",
        "✅ No overlap between input sequences (stride = max_length).\n",
        "\n",
        "# 3️⃣ Visual way to think\n",
        "- Tokens:  0 1 2 3 4 5 6 7 8 9\n",
        "- Window: [0 1 2 3]  -> stride=1 -> next window starts at 1\n",
        "- Window:   [1 2 3 4]  -> stride=1 -> next window starts at 2\n",
        "- Window:     [2 3 4 5] ...\n",
        "\n",
        "\n",
        "Smaller stride → more overlap → more training examples → slower but better learning.\n",
        "\n",
        "Larger stride → fewer examples → faster, less redundancy.\n",
        "\n",
        "# 4️⃣ TL;DR\n",
        "\n",
        "- Stride = how many tokens to skip forward for the next input-output pair.\n",
        "\n",
        "- Stride = 1 → move 1 token → inputs highly overlap.\n",
        "\n",
        " - Stride = max_length → no overlap."
      ],
      "metadata": {
        "id": "Ve8K334qtVzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Why i : i + max_length for input\n",
        "# input_row_pair = token_ids[i : i + max_length]\n",
        "\n",
        "\n",
        "# This takes max_length tokens starting at position i.\n",
        "\n",
        "# Example:\n",
        "\n",
        "# token_ids = [0,1,2,3,4,5,6,7,8]\n",
        "# max_length = 4\n",
        "# stride = 1\n",
        "\n",
        "# i = 0  → token_ids[0:4] = [0,1,2,3]  (first input sequence)\n",
        "# i = 1  → token_ids[1:5] = [1,2,3,4]  (next input sequence)\n",
        "# ✅ So i shifts the window along the sequence.\n",
        "\n"
      ],
      "metadata": {
        "id": "aGZcRObWpgI7"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import tiktoken\n",
        "\n",
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt)\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_row_pair = token_ids[i : i + max_length]\n",
        "            output_row_pair = token_ids[i + 1 : i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_row_pair))\n",
        "            self.target_ids.append(torch.tensor(output_row_pair))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_data_loader(txt, batch_size, stride=128, max_length=256, drop_last=True, shuffle=True, num_workers=0):\n",
        "    # Fixed: get_encoding() instead of encoding_name_for_model()\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset = GPTDataset(txt, tokenizer=tokenizer, max_length=max_length, stride=stride)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, drop_last=drop_last)\n",
        "    return dataloader\n"
      ],
      "metadata": {
        "id": "5rzZRXsmxt-S"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "data_loader = create_data_loader(data, batch_size=8, stride=3, max_length=4, shuffle=False)\n",
        "data_iter =iter(data_loader)\n",
        "first_batch = next(data_iter)"
      ],
      "metadata": {
        "id": "eJeKQBFQtxkl"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1WwgRGGyYeZ",
        "outputId": "f72ea88e-aea2-49a3-8621-123aaa55fe43"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[10970, 33310,    35, 18379],\n",
              "         [18379, 15749, 40417,    40],\n",
              "         [   40,   550,  1464,  1807],\n",
              "         [ 1807,  3619,   402,   271],\n",
              "         [  271, 10899,  2138,   257],\n",
              "         [  257,  7026, 15632,   438],\n",
              "         [  438,  2016,   556,   702],\n",
              "         [  702,  5891,  1576,   438]]),\n",
              " tensor([[33310,    35, 18379, 15749],\n",
              "         [15749, 40417,    40,   550],\n",
              "         [  550,  1464,  1807,  3619],\n",
              "         [ 3619,   402,   271, 10899],\n",
              "         [10899,  2138,   257,  7026],\n",
              "         [ 7026, 15632,   438,  2016],\n",
              "         [ 2016,   556,   702,  5891],\n",
              "         [ 5891,  1576,   438,   568]])]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    }
  ]
}