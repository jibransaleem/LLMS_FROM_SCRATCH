{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UIeRHOXjKN",
        "outputId": "c08e7e4d-42d7-4ed4-d0c6-3c20a7a54b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "try :\n",
        "  import gensim.downloader as api\n",
        "except Exception :\n",
        "  !pip install gensim\n",
        "  import gensim.downloader as api\n",
        "model = api.load(\"word2vec-google-news-300\")  # download the model and return as object ready for use"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "try :\n",
        "  import tiktoken\n",
        "except Excepion:\n",
        "  !pip install tiktoken\n",
        "  import tiktoken"
      ],
      "metadata": {
        "id": "_qD6rdsBZE2_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDj2aVVihDGJ",
        "outputId": "df5cf7b2-1fc9-4113-b86b-3ee2f4970489"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "RO4Ze8pbhaXu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"The quick brown fox jumps over the lazy dog.\""
      ],
      "metadata": {
        "id": "UWtF4DYZgqEi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting into tokens\n",
        "# using simple word tokenizer\n",
        "tokens = np.sort(np.array(word_tokenize(txt)))\n"
      ],
      "metadata": {
        "id": "DVHCnPkWg9If"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d ={}\n",
        "for index , token in enumerate(tokens):\n",
        "  d[index] = str(token)"
      ],
      "metadata": {
        "id": "8_EGRN0YhdWp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids =list(d.keys())"
      ],
      "metadata": {
        "id": "HhikSCpih_aK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_token_id  =token_ids[4:]"
      ],
      "metadata": {
        "id": "H5eQVH2oiZI7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_id_tensor =torch.tensor(temp_token_id )\n"
      ],
      "metadata": {
        "id": "IkBNlE1DiQfk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_id_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPbBdQZbii4d",
        "outputId": "79add56c-1201-4835-eafa-ea4e66c7d95d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_dim =  3 # columns\n",
        "vector_size = 6  # rows"
      ],
      "metadata": {
        "id": "yHxYCKHOipNN"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vDxL04ijMBi",
        "outputId": "9e3d10ec-3d1b-4b45-b19c-6b9d1db65885"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d168d5f5d70>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embading_layer = torch.nn.Embedding(vector_size , vector_dim)"
      ],
      "metadata": {
        "id": "nO5zfPiljXpI"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embading_layer.weight # inital random weights\n",
        "# each row index = one token id\n",
        "# for example the first row weights : [-0.1320, -0.1254, -0.1610] refers to th weights of work with token id = 0\n",
        "#  tensor([[-0.1320, -0.1254, -0.1610],  # token ID 0\n",
        "#         [-0.8372, -1.2945, -0.2623],  # token ID 1\n",
        "#         [-0.5353,  1.3466, -0.6958],  # token ID 2\n",
        "#         [-0.0522,  0.4924, -0.6921],  # token ID 3\n",
        "#         [-0.6944, -0.2125,  0.2362],  # token ID 4\n",
        "#         [-1.2438,  1.4400,  0.7946]], # token ID 5\n",
        "#        requires_grad=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWanv4h8jlxO",
        "outputId": "88b80843-8c5d-4fff-ac80-32d31e175e57"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.1320, -0.1254, -0.1610],\n",
              "        [-0.8372, -1.2945, -0.2623],\n",
              "        [-0.5353,  1.3466, -0.6958],\n",
              "        [-0.0522,  0.4924, -0.6921],\n",
              "        [-0.6944, -0.2125,  0.2362],\n",
              "        [-1.2438,  1.4400,  0.7946]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fetching embaded vector by  token id\n",
        "token_id = torch.tensor([[3]]) # needed id in tensor cz embading layer in tensor\n",
        "#looks for a partilar row/token id and retrives that for u\n",
        "embading_layer(token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynDGlWdnk4mc",
        "outputId": "09cfa991-b524-4a5b-912a-ae003fc365e2"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0522,  0.4924, -0.6921]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#emabding layer is also called look up table\n",
        "# cz you just have to see row number for a particular token id"
      ],
      "metadata": {
        "id": "R2mGAW9olYQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_token_id = [0, 1, 2]\n",
        "\n",
        "# Convert token IDs to a LongTensor\n",
        "input_tensor = torch.tensor(temp_token_id)\n",
        "\n",
        "# Pass through embedding layer\n",
        "embeddings = embading_layer(input_tensor)\n",
        "\n",
        "print(embeddings)\n",
        "print(embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hzllnN9j6zz",
        "outputId": "b7a545c6-0d19-43ea-876e-a8a87c42e3a9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1320, -0.1254, -0.1610],\n",
            "        [-0.8372, -1.2945, -0.2623],\n",
            "        [-0.5353,  1.3466, -0.6958]], grad_fn=<EmbeddingBackward0>)\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p2iwaTrfnTSN"
      },
      "execution_count": 82,
      "outputs": []
    }
  ]
}